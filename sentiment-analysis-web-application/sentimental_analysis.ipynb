{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %mkdir ../data\n",
    "# !wget -O ../data/aclImdb_v1.tar.gz http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "# !tar -zxf ../data/aclImdb_v1.tar.gz -C ../data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "def read_imdb_data(data_dir='../data/aclImdb'):\n",
    "    data = {}\n",
    "    labels = {}\n",
    "    \n",
    "    for data_type in ['train', 'test']:\n",
    "        data[data_type] = {}\n",
    "        labels[data_type] = {}\n",
    "        \n",
    "        for sentiment in ['pos', 'neg']:\n",
    "            data[data_type][sentiment] = []\n",
    "            labels[data_type][sentiment] = []\n",
    "            \n",
    "            path = os.path.join(data_dir, data_type, sentiment, '*.txt')\n",
    "            files = glob.glob(path)\n",
    "            \n",
    "            for f in files:\n",
    "                with open(f) as review:\n",
    "                    data[data_type][sentiment].append(review.read())\n",
    "                    # Here we represent a positive review by '1' and a negative review by '0'\n",
    "                    labels[data_type][sentiment].append(1 if sentiment == 'pos' else 0)\n",
    "                    \n",
    "            assert len(data[data_type][sentiment]) == len(labels[data_type][sentiment]), \\\n",
    "                    \"{}/{} data size does not match labels size\".format(data_type, sentiment)\n",
    "                \n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMDB reviews: train = 12500 pos / 12500 neg, test = 12500 pos / 12500 neg\n"
     ]
    }
   ],
   "source": [
    "data, labels = read_imdb_data()\n",
    "print(\"IMDB reviews: train = {} pos / {} neg, test = {} pos / {} neg\".format(\n",
    "            len(data['train']['pos']), len(data['train']['neg']),\n",
    "            len(data['test']['pos']), len(data['test']['neg'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "def prepare_imdb_data(data, labels):\n",
    "    \"\"\"Prepare training and test sets from IMDb movie reviews.\"\"\"\n",
    "    \n",
    "    #Combine positive and negative reviews and labels\n",
    "    data_train = data['train']['pos'] + data['train']['neg']\n",
    "    data_test = data['test']['pos'] + data['test']['neg']\n",
    "    labels_train = labels['train']['pos'] + labels['train']['neg']\n",
    "    labels_test = labels['test']['pos'] + labels['test']['neg']\n",
    "    \n",
    "    #Shuffle reviews and corresponding labels within training and test sets\n",
    "    data_train, labels_train = shuffle(data_train, labels_train)\n",
    "    data_test, labels_test = shuffle(data_test, labels_test)\n",
    "    \n",
    "    # Return a unified training data, test data, training labels, test labets\n",
    "    return data_train, data_test, labels_train, labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMDb reviews (combined): train = 25000, test = 25000\n"
     ]
    }
   ],
   "source": [
    "train_X, test_X, train_y, test_y = prepare_imdb_data(data, labels)\n",
    "print(\"IMDb reviews (combined): train = {}, test = {}\".format(len(train_X), len(test_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a famous essay he wrote about Charles Dickens, George Orwell points out that many readers always regretted that Dickens never continued writing like he did in PICKWICK PAPERS: that is, he did not stick to writing funny episodic novels for the rest of his career. This would not have been too difficult for Dickens. His contemporary Robert Surtees did precisely that, only concentrating on the misadventures of the fox hunting set (MR. FANCY ROMFORD'S HOUNDS is a title of one of his novels). Among hunters and horse lovers Surtees still has a following but most people find his novels unreadable. Dickens was determined to show he was more than a funny man (and don't forget, his first book, SKETCHES BY BOZ, was also a funny book). So Dickens third book is OLIVER TWIST (which got pretty grim at points). Orwell says that for any author to grow they have to change the style of their books. Dickens would definitely (and successfully) have agreed to that.<br /><br />But Orwell overlooked the genre writer who transcends his fellows. Surtees, as I said, is a genre writer concentrating on hunting - but not everyone is interested in hunting. But P.G.Wodehouse saw himself as an entertainer, poking fun at the upper reaches of the British social system. His Earl of Emsworth is prouder of raising the finest pig in England than being...well Earl of Emsworth! His Psmith is always prepared to counterattack when he is supposed to be submissive to an unfair superior. His Stanley Uckridge will always have a \"perfect\" scheme that should net a huge profit (but always manages to come apart at the end). And best of all, his Jeeves will always put his brilliant brain to work rescuing the inept Bertie Wooster, his boss. Since Wodehouse had a limited view of his mission as a writer - he was there to do cartoon figures of fun for the entertainment of the world - his books never lost their glow. They served (and still serve) their purposes. In fact, compared Wodehouse with his far more serious contemporary Evelyn Waugh, who also wrote funny books, but of a more intellectual type. The best of Waugh remains among the high points of 20th Century British literature: BRIDESHEAD REVISITED, DECLINE AND FALL, and the rest. But in his determination to make his points, if his points failed to interest the reader the book frequently collapsed. For every VILE BODIES there was some failure late in his career like THE ORDEAL OF GILBERT PINFOLD. While Wodehouse could do lesser hack work too, his falling did not go as far as Waugh's did.<br /><br />Wodehouse also was a gifted lyricist (when you hear \"Bill\" in the score of SHOWBOAT, it is not Kern and Hammerstein's tune, but Kern and Wodehouse's tune transposed from \"Oh Lady, Lady\" a dozen years earlier). He was a handy dramatist too. So it is pleasing to see that he took his novel A DAMSEL IN DISTRESS and turned it into the screenplay here.<br /><br />It has the normal Wodehouse touches. That perfect butler Keggs (Reginald Gardiner in a wonderful performance) is a scoundrel in rigging a \"friendly\" gambling game of chance among the staff of the stately home he heads. He is also unable to refrain, occasionally, from singing Italian opera - despite Constance Collier's attempts to control his impulse. This is typical Wodehouse characterization. So is the way the love affair between Lady Alyce and Jerry keeps going well and going down due to the antics of Keggs and young Albert, both of whom want to win that game of chance pot of cash. Wodehouse always does that type of plot switch, with antagonists switching their point of view depending on their present state of interest.<br /><br />Wodehouse was also lucky here to have Burns and Allan to work with. It is generally considered that of all the films they made as supporting actors together (such as SIX OF A KIND and WE'RE NOT DRESSING) George and Gracie did their best support with Fred Astaire. The Fun House sequence, which includes the song \"Stiff Upper Lip\", is wonderful, as is an earlier sequence where the three do a \"whisk broom\" dance (that Astaire learned from Burns). But Gracie's marvelous illogical logic is used by Wodehouse in scenes with Gardiner (see how she manages to confuse him into giving her more money than her change deserves to be - only Albert happens to notice Keggs/Gardiner's mistake, and looks at Gardiner as though he's either stupid or mad). Her dialog with Lady Caroline (Collier)'s son Reggie (Ray Noble, the British band leader)leading him to imagine that he will marry her, but saying goodbye to Gracie as she drives off with George to get married is wonderful too.<br /><br />The film supposedly failed at the box office because of the lack of Ginger Rogers in it, and the weakness of Joan Fontaine. Fontaine is not doing a remarkable job in the role, but the flaw is really Wodehouse's - he didn't make the character very interesting. But the film can stand without that, given the other performers and their characters, Gershwin's music, and Wodehouse's marvelous sense of fun.\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(train_X[100])\n",
    "print(train_y[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5034\n"
     ]
    }
   ],
   "source": [
    "print(len(train_X[100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (3.8.1)\r\n",
      "Requirement already satisfied: click in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from nltk) (8.1.7)\r\n",
      "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from nltk) (1.3.2)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from nltk) (2023.10.3)\r\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from nltk) (4.66.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def review_to_words(review):\n",
    "    nltk.download(\"stopwords\", quiet=True)\n",
    "    stemmer = PorterStemmer()\n",
    "    \n",
    "    text = BeautifulSoup(review, \"html.parser\").get_text() # Remove HTML tags\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower()) # Convert to lower case\n",
    "    words = text.split() # Split string into words\n",
    "    words = [w for w in words if w not in stopwords.words(\"english\")] # Remove stopwords\n",
    "    words = [PorterStemmer().stem(w) for w in words] # stem\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['famou',\n",
       " 'essay',\n",
       " 'wrote',\n",
       " 'charl',\n",
       " 'dicken',\n",
       " 'georg',\n",
       " 'orwel',\n",
       " 'point',\n",
       " 'mani',\n",
       " 'reader',\n",
       " 'alway',\n",
       " 'regret',\n",
       " 'dicken',\n",
       " 'never',\n",
       " 'continu',\n",
       " 'write',\n",
       " 'like',\n",
       " 'pickwick',\n",
       " 'paper',\n",
       " 'stick',\n",
       " 'write',\n",
       " 'funni',\n",
       " 'episod',\n",
       " 'novel',\n",
       " 'rest',\n",
       " 'career',\n",
       " 'would',\n",
       " 'difficult',\n",
       " 'dicken',\n",
       " 'contemporari',\n",
       " 'robert',\n",
       " 'surte',\n",
       " 'precis',\n",
       " 'concentr',\n",
       " 'misadventur',\n",
       " 'fox',\n",
       " 'hunt',\n",
       " 'set',\n",
       " 'mr',\n",
       " 'fanci',\n",
       " 'romford',\n",
       " 'hound',\n",
       " 'titl',\n",
       " 'one',\n",
       " 'novel',\n",
       " 'among',\n",
       " 'hunter',\n",
       " 'hors',\n",
       " 'lover',\n",
       " 'surte',\n",
       " 'still',\n",
       " 'follow',\n",
       " 'peopl',\n",
       " 'find',\n",
       " 'novel',\n",
       " 'unread',\n",
       " 'dicken',\n",
       " 'determin',\n",
       " 'show',\n",
       " 'funni',\n",
       " 'man',\n",
       " 'forget',\n",
       " 'first',\n",
       " 'book',\n",
       " 'sketch',\n",
       " 'boz',\n",
       " 'also',\n",
       " 'funni',\n",
       " 'book',\n",
       " 'dicken',\n",
       " 'third',\n",
       " 'book',\n",
       " 'oliv',\n",
       " 'twist',\n",
       " 'got',\n",
       " 'pretti',\n",
       " 'grim',\n",
       " 'point',\n",
       " 'orwel',\n",
       " 'say',\n",
       " 'author',\n",
       " 'grow',\n",
       " 'chang',\n",
       " 'style',\n",
       " 'book',\n",
       " 'dicken',\n",
       " 'would',\n",
       " 'definit',\n",
       " 'success',\n",
       " 'agre',\n",
       " 'orwel',\n",
       " 'overlook',\n",
       " 'genr',\n",
       " 'writer',\n",
       " 'transcend',\n",
       " 'fellow',\n",
       " 'surte',\n",
       " 'said',\n",
       " 'genr',\n",
       " 'writer',\n",
       " 'concentr',\n",
       " 'hunt',\n",
       " 'everyon',\n",
       " 'interest',\n",
       " 'hunt',\n",
       " 'p',\n",
       " 'g',\n",
       " 'wodehous',\n",
       " 'saw',\n",
       " 'entertain',\n",
       " 'poke',\n",
       " 'fun',\n",
       " 'upper',\n",
       " 'reach',\n",
       " 'british',\n",
       " 'social',\n",
       " 'system',\n",
       " 'earl',\n",
       " 'emsworth',\n",
       " 'prouder',\n",
       " 'rais',\n",
       " 'finest',\n",
       " 'pig',\n",
       " 'england',\n",
       " 'well',\n",
       " 'earl',\n",
       " 'emsworth',\n",
       " 'psmith',\n",
       " 'alway',\n",
       " 'prepar',\n",
       " 'counterattack',\n",
       " 'suppos',\n",
       " 'submiss',\n",
       " 'unfair',\n",
       " 'superior',\n",
       " 'stanley',\n",
       " 'uckridg',\n",
       " 'alway',\n",
       " 'perfect',\n",
       " 'scheme',\n",
       " 'net',\n",
       " 'huge',\n",
       " 'profit',\n",
       " 'alway',\n",
       " 'manag',\n",
       " 'come',\n",
       " 'apart',\n",
       " 'end',\n",
       " 'best',\n",
       " 'jeev',\n",
       " 'alway',\n",
       " 'put',\n",
       " 'brilliant',\n",
       " 'brain',\n",
       " 'work',\n",
       " 'rescu',\n",
       " 'inept',\n",
       " 'berti',\n",
       " 'wooster',\n",
       " 'boss',\n",
       " 'sinc',\n",
       " 'wodehous',\n",
       " 'limit',\n",
       " 'view',\n",
       " 'mission',\n",
       " 'writer',\n",
       " 'cartoon',\n",
       " 'figur',\n",
       " 'fun',\n",
       " 'entertain',\n",
       " 'world',\n",
       " 'book',\n",
       " 'never',\n",
       " 'lost',\n",
       " 'glow',\n",
       " 'serv',\n",
       " 'still',\n",
       " 'serv',\n",
       " 'purpos',\n",
       " 'fact',\n",
       " 'compar',\n",
       " 'wodehous',\n",
       " 'far',\n",
       " 'seriou',\n",
       " 'contemporari',\n",
       " 'evelyn',\n",
       " 'waugh',\n",
       " 'also',\n",
       " 'wrote',\n",
       " 'funni',\n",
       " 'book',\n",
       " 'intellectu',\n",
       " 'type',\n",
       " 'best',\n",
       " 'waugh',\n",
       " 'remain',\n",
       " 'among',\n",
       " 'high',\n",
       " 'point',\n",
       " '20th',\n",
       " 'centuri',\n",
       " 'british',\n",
       " 'literatur',\n",
       " 'brideshead',\n",
       " 'revisit',\n",
       " 'declin',\n",
       " 'fall',\n",
       " 'rest',\n",
       " 'determin',\n",
       " 'make',\n",
       " 'point',\n",
       " 'point',\n",
       " 'fail',\n",
       " 'interest',\n",
       " 'reader',\n",
       " 'book',\n",
       " 'frequent',\n",
       " 'collaps',\n",
       " 'everi',\n",
       " 'vile',\n",
       " 'bodi',\n",
       " 'failur',\n",
       " 'late',\n",
       " 'career',\n",
       " 'like',\n",
       " 'ordeal',\n",
       " 'gilbert',\n",
       " 'pinfold',\n",
       " 'wodehous',\n",
       " 'could',\n",
       " 'lesser',\n",
       " 'hack',\n",
       " 'work',\n",
       " 'fall',\n",
       " 'go',\n",
       " 'far',\n",
       " 'waugh',\n",
       " 'wodehous',\n",
       " 'also',\n",
       " 'gift',\n",
       " 'lyricist',\n",
       " 'hear',\n",
       " 'bill',\n",
       " 'score',\n",
       " 'showboat',\n",
       " 'kern',\n",
       " 'hammerstein',\n",
       " 'tune',\n",
       " 'kern',\n",
       " 'wodehous',\n",
       " 'tune',\n",
       " 'transpos',\n",
       " 'oh',\n",
       " 'ladi',\n",
       " 'ladi',\n",
       " 'dozen',\n",
       " 'year',\n",
       " 'earlier',\n",
       " 'handi',\n",
       " 'dramatist',\n",
       " 'pleas',\n",
       " 'see',\n",
       " 'took',\n",
       " 'novel',\n",
       " 'damsel',\n",
       " 'distress',\n",
       " 'turn',\n",
       " 'screenplay',\n",
       " 'normal',\n",
       " 'wodehous',\n",
       " 'touch',\n",
       " 'perfect',\n",
       " 'butler',\n",
       " 'kegg',\n",
       " 'reginald',\n",
       " 'gardin',\n",
       " 'wonder',\n",
       " 'perform',\n",
       " 'scoundrel',\n",
       " 'rig',\n",
       " 'friendli',\n",
       " 'gambl',\n",
       " 'game',\n",
       " 'chanc',\n",
       " 'among',\n",
       " 'staff',\n",
       " 'state',\n",
       " 'home',\n",
       " 'head',\n",
       " 'also',\n",
       " 'unabl',\n",
       " 'refrain',\n",
       " 'occasion',\n",
       " 'sing',\n",
       " 'italian',\n",
       " 'opera',\n",
       " 'despit',\n",
       " 'constanc',\n",
       " 'collier',\n",
       " 'attempt',\n",
       " 'control',\n",
       " 'impuls',\n",
       " 'typic',\n",
       " 'wodehous',\n",
       " 'character',\n",
       " 'way',\n",
       " 'love',\n",
       " 'affair',\n",
       " 'ladi',\n",
       " 'alyc',\n",
       " 'jerri',\n",
       " 'keep',\n",
       " 'go',\n",
       " 'well',\n",
       " 'go',\n",
       " 'due',\n",
       " 'antic',\n",
       " 'kegg',\n",
       " 'young',\n",
       " 'albert',\n",
       " 'want',\n",
       " 'win',\n",
       " 'game',\n",
       " 'chanc',\n",
       " 'pot',\n",
       " 'cash',\n",
       " 'wodehous',\n",
       " 'alway',\n",
       " 'type',\n",
       " 'plot',\n",
       " 'switch',\n",
       " 'antagonist',\n",
       " 'switch',\n",
       " 'point',\n",
       " 'view',\n",
       " 'depend',\n",
       " 'present',\n",
       " 'state',\n",
       " 'interest',\n",
       " 'wodehous',\n",
       " 'also',\n",
       " 'lucki',\n",
       " 'burn',\n",
       " 'allan',\n",
       " 'work',\n",
       " 'gener',\n",
       " 'consid',\n",
       " 'film',\n",
       " 'made',\n",
       " 'support',\n",
       " 'actor',\n",
       " 'togeth',\n",
       " 'six',\n",
       " 'kind',\n",
       " 'dress',\n",
       " 'georg',\n",
       " 'graci',\n",
       " 'best',\n",
       " 'support',\n",
       " 'fred',\n",
       " 'astair',\n",
       " 'fun',\n",
       " 'hous',\n",
       " 'sequenc',\n",
       " 'includ',\n",
       " 'song',\n",
       " 'stiff',\n",
       " 'upper',\n",
       " 'lip',\n",
       " 'wonder',\n",
       " 'earlier',\n",
       " 'sequenc',\n",
       " 'three',\n",
       " 'whisk',\n",
       " 'broom',\n",
       " 'danc',\n",
       " 'astair',\n",
       " 'learn',\n",
       " 'burn',\n",
       " 'graci',\n",
       " 'marvel',\n",
       " 'illog',\n",
       " 'logic',\n",
       " 'use',\n",
       " 'wodehous',\n",
       " 'scene',\n",
       " 'gardin',\n",
       " 'see',\n",
       " 'manag',\n",
       " 'confus',\n",
       " 'give',\n",
       " 'money',\n",
       " 'chang',\n",
       " 'deserv',\n",
       " 'albert',\n",
       " 'happen',\n",
       " 'notic',\n",
       " 'kegg',\n",
       " 'gardin',\n",
       " 'mistak',\n",
       " 'look',\n",
       " 'gardin',\n",
       " 'though',\n",
       " 'either',\n",
       " 'stupid',\n",
       " 'mad',\n",
       " 'dialog',\n",
       " 'ladi',\n",
       " 'carolin',\n",
       " 'collier',\n",
       " 'son',\n",
       " 'reggi',\n",
       " 'ray',\n",
       " 'nobl',\n",
       " 'british',\n",
       " 'band',\n",
       " 'leader',\n",
       " 'lead',\n",
       " 'imagin',\n",
       " 'marri',\n",
       " 'say',\n",
       " 'goodby',\n",
       " 'graci',\n",
       " 'drive',\n",
       " 'georg',\n",
       " 'get',\n",
       " 'marri',\n",
       " 'wonder',\n",
       " 'film',\n",
       " 'supposedli',\n",
       " 'fail',\n",
       " 'box',\n",
       " 'offic',\n",
       " 'lack',\n",
       " 'ginger',\n",
       " 'roger',\n",
       " 'weak',\n",
       " 'joan',\n",
       " 'fontain',\n",
       " 'fontain',\n",
       " 'remark',\n",
       " 'job',\n",
       " 'role',\n",
       " 'flaw',\n",
       " 'realli',\n",
       " 'wodehous',\n",
       " 'make',\n",
       " 'charact',\n",
       " 'interest',\n",
       " 'film',\n",
       " 'stand',\n",
       " 'without',\n",
       " 'given',\n",
       " 'perform',\n",
       " 'charact',\n",
       " 'gershwin',\n",
       " 'music',\n",
       " 'wodehous',\n",
       " 'marvel',\n",
       " 'sens',\n",
       " 'fun']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_to_words(train_X[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "cache_dir = os.path.join(\"../cache\", \"sentiment_analysis\")  # where to store cache files\n",
    "os.makedirs(cache_dir, exist_ok=True)  # ensure cache directory exists\n",
    "\n",
    "def preprocess_data(data_train, data_test, labels_train, labels_test,\n",
    "                    cache_dir=cache_dir, cache_file=\"preprocessed_data.pkl\"):\n",
    "        cache_data = None\n",
    "        if cache_file is not None:\n",
    "            try:\n",
    "                with open(os.path.join(cache_dir, cache_file), \"rb\") as f:\n",
    "                    cache_data = pickle.load(f)\n",
    "                print(\"Read preprocessed data from cache file:\", cache_file)\n",
    "            except:\n",
    "                pass  # unable to read from cache, but that's okay\n",
    "    \n",
    "        if cache_data is None:\n",
    "            words_train = [review_to_words(review) for review in data_train]\n",
    "            words_test = [review_to_words(review) for review in data_test]\n",
    "        \n",
    "            # Write to cache file for future runs\n",
    "            if cache_file is not None:\n",
    "                cache_data = dict(words_train=words_train, words_test=words_test,\n",
    "                                  labels_train=labels_train, labels_test=labels_test)\n",
    "                with open(os.path.join(cache_dir, cache_file), \"wb\") as f:\n",
    "                    pickle.dump(cache_data, f)\n",
    "                    print(\"Wrote preprocessed data to cache file:\", cache_file)\n",
    "        else:\n",
    "            # Unpack data loaded from cache file\n",
    "            words_train, words_test, labels_train, labels_test = (cache_data['words_train'],\n",
    "                    cache_data['words_test'], cache_data['labels_train'], cache_data['labels_test'])\n",
    "\n",
    "        return words_train, words_test, labels_train, labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read preprocessed data from cache file: preprocessed_data.pkl\n"
     ]
    }
   ],
   "source": [
    "# Preprocess data\n",
    "train_X, test_X, train_y, test_y = preprocess_data(train_X, test_X, train_y, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def build_dict(data, vocab_size = 5000):\n",
    "    word_count = {} # A dict storing the words that appear in the reviews along with how often they occur\n",
    "    \n",
    "    for item in data:\n",
    "        for word in item:\n",
    "            if word not in word_count:\n",
    "                word_count[word] = 1\n",
    "            else:\n",
    "                word_count[word] +=1\n",
    "    \n",
    "    sorted_words = sorted(word_count, key=word_count.get, reverse=True)\n",
    "    \n",
    "    word_dict = {} # This is what we are building, a dictionary that translates words into integers\n",
    "    for idx, word in enumerate(sorted_words[:vocab_size - 2]): \n",
    "        word_dict[word] = idx + 2                              \n",
    "        \n",
    "    return word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'movi': 2,\n",
       " 'film': 3,\n",
       " 'one': 4,\n",
       " 'like': 5,\n",
       " 'time': 6,\n",
       " 'good': 7,\n",
       " 'make': 8,\n",
       " 'charact': 9,\n",
       " 'get': 10,\n",
       " 'see': 11,\n",
       " 'watch': 12,\n",
       " 'stori': 13,\n",
       " 'even': 14,\n",
       " 'would': 15,\n",
       " 'realli': 16,\n",
       " 'well': 17,\n",
       " 'scene': 18,\n",
       " 'look': 19,\n",
       " 'show': 20,\n",
       " 'much': 21,\n",
       " 'end': 22,\n",
       " 'peopl': 23,\n",
       " 'bad': 24,\n",
       " 'go': 25,\n",
       " 'great': 26,\n",
       " 'also': 27,\n",
       " 'first': 28,\n",
       " 'love': 29,\n",
       " 'think': 30,\n",
       " 'way': 31,\n",
       " 'act': 32,\n",
       " 'play': 33,\n",
       " 'made': 34,\n",
       " 'thing': 35,\n",
       " 'could': 36,\n",
       " 'know': 37,\n",
       " 'say': 38,\n",
       " 'seem': 39,\n",
       " 'work': 40,\n",
       " 'plot': 41,\n",
       " 'two': 42,\n",
       " 'actor': 43,\n",
       " 'year': 44,\n",
       " 'come': 45,\n",
       " 'mani': 46,\n",
       " 'seen': 47,\n",
       " 'take': 48,\n",
       " 'life': 49,\n",
       " 'want': 50,\n",
       " 'never': 51,\n",
       " 'littl': 52,\n",
       " 'best': 53,\n",
       " 'tri': 54,\n",
       " 'man': 55,\n",
       " 'ever': 56,\n",
       " 'give': 57,\n",
       " 'better': 58,\n",
       " 'still': 59,\n",
       " 'perform': 60,\n",
       " 'find': 61,\n",
       " 'feel': 62,\n",
       " 'part': 63,\n",
       " 'back': 64,\n",
       " 'use': 65,\n",
       " 'someth': 66,\n",
       " 'director': 67,\n",
       " 'actual': 68,\n",
       " 'interest': 69,\n",
       " 'lot': 70,\n",
       " 'real': 71,\n",
       " 'old': 72,\n",
       " 'cast': 73,\n",
       " 'though': 74,\n",
       " 'live': 75,\n",
       " 'star': 76,\n",
       " 'enjoy': 77,\n",
       " 'guy': 78,\n",
       " 'anoth': 79,\n",
       " 'new': 80,\n",
       " 'role': 81,\n",
       " 'noth': 82,\n",
       " '10': 83,\n",
       " 'funni': 84,\n",
       " 'music': 85,\n",
       " 'point': 86,\n",
       " 'start': 87,\n",
       " 'set': 88,\n",
       " 'girl': 89,\n",
       " 'origin': 90,\n",
       " 'day': 91,\n",
       " 'world': 92,\n",
       " 'everi': 93,\n",
       " 'believ': 94,\n",
       " 'turn': 95,\n",
       " 'quit': 96,\n",
       " 'direct': 97,\n",
       " 'us': 98,\n",
       " 'thought': 99,\n",
       " 'fact': 100,\n",
       " 'minut': 101,\n",
       " 'horror': 102,\n",
       " 'kill': 103,\n",
       " 'action': 104,\n",
       " 'comedi': 105,\n",
       " 'pretti': 106,\n",
       " 'young': 107,\n",
       " 'wonder': 108,\n",
       " 'happen': 109,\n",
       " 'around': 110,\n",
       " 'got': 111,\n",
       " 'effect': 112,\n",
       " 'right': 113,\n",
       " 'long': 114,\n",
       " 'howev': 115,\n",
       " 'big': 116,\n",
       " 'line': 117,\n",
       " 'famili': 118,\n",
       " 'enough': 119,\n",
       " 'seri': 120,\n",
       " 'may': 121,\n",
       " 'need': 122,\n",
       " 'fan': 123,\n",
       " 'bit': 124,\n",
       " 'script': 125,\n",
       " 'beauti': 126,\n",
       " 'person': 127,\n",
       " 'becom': 128,\n",
       " 'without': 129,\n",
       " 'must': 130,\n",
       " 'alway': 131,\n",
       " 'friend': 132,\n",
       " 'tell': 133,\n",
       " 'reason': 134,\n",
       " 'saw': 135,\n",
       " 'last': 136,\n",
       " 'final': 137,\n",
       " 'kid': 138,\n",
       " 'almost': 139,\n",
       " 'put': 140,\n",
       " 'least': 141,\n",
       " 'sure': 142,\n",
       " 'done': 143,\n",
       " 'whole': 144,\n",
       " 'place': 145,\n",
       " 'complet': 146,\n",
       " 'kind': 147,\n",
       " 'differ': 148,\n",
       " 'expect': 149,\n",
       " 'shot': 150,\n",
       " 'far': 151,\n",
       " 'mean': 152,\n",
       " 'anyth': 153,\n",
       " 'book': 154,\n",
       " 'laugh': 155,\n",
       " 'might': 156,\n",
       " 'name': 157,\n",
       " 'sinc': 158,\n",
       " 'begin': 159,\n",
       " '2': 160,\n",
       " 'probabl': 161,\n",
       " 'woman': 162,\n",
       " 'help': 163,\n",
       " 'entertain': 164,\n",
       " 'let': 165,\n",
       " 'screen': 166,\n",
       " 'call': 167,\n",
       " 'tv': 168,\n",
       " 'moment': 169,\n",
       " 'away': 170,\n",
       " 'read': 171,\n",
       " 'yet': 172,\n",
       " 'rather': 173,\n",
       " 'worst': 174,\n",
       " 'run': 175,\n",
       " 'fun': 176,\n",
       " 'lead': 177,\n",
       " 'hard': 178,\n",
       " 'audienc': 179,\n",
       " 'idea': 180,\n",
       " 'anyon': 181,\n",
       " 'episod': 182,\n",
       " 'american': 183,\n",
       " 'found': 184,\n",
       " 'appear': 185,\n",
       " 'bore': 186,\n",
       " 'especi': 187,\n",
       " 'although': 188,\n",
       " 'hope': 189,\n",
       " 'cours': 190,\n",
       " 'keep': 191,\n",
       " 'anim': 192,\n",
       " 'job': 193,\n",
       " 'goe': 194,\n",
       " 'move': 195,\n",
       " 'sens': 196,\n",
       " 'version': 197,\n",
       " 'dvd': 198,\n",
       " 'war': 199,\n",
       " 'money': 200,\n",
       " 'someon': 201,\n",
       " 'mind': 202,\n",
       " 'mayb': 203,\n",
       " 'problem': 204,\n",
       " 'true': 205,\n",
       " 'hous': 206,\n",
       " 'everyth': 207,\n",
       " 'nice': 208,\n",
       " 'second': 209,\n",
       " 'rate': 210,\n",
       " 'three': 211,\n",
       " 'night': 212,\n",
       " 'face': 213,\n",
       " 'follow': 214,\n",
       " 'recommend': 215,\n",
       " 'product': 216,\n",
       " 'main': 217,\n",
       " 'worth': 218,\n",
       " 'leav': 219,\n",
       " 'human': 220,\n",
       " 'special': 221,\n",
       " 'excel': 222,\n",
       " 'togeth': 223,\n",
       " 'wast': 224,\n",
       " 'everyon': 225,\n",
       " 'sound': 226,\n",
       " 'john': 227,\n",
       " 'hand': 228,\n",
       " '1': 229,\n",
       " 'father': 230,\n",
       " 'later': 231,\n",
       " 'eye': 232,\n",
       " 'said': 233,\n",
       " 'view': 234,\n",
       " 'instead': 235,\n",
       " 'review': 236,\n",
       " 'boy': 237,\n",
       " 'high': 238,\n",
       " 'hour': 239,\n",
       " 'miss': 240,\n",
       " 'classic': 241,\n",
       " 'talk': 242,\n",
       " 'wife': 243,\n",
       " 'understand': 244,\n",
       " 'left': 245,\n",
       " 'care': 246,\n",
       " 'black': 247,\n",
       " 'death': 248,\n",
       " 'open': 249,\n",
       " 'murder': 250,\n",
       " 'write': 251,\n",
       " 'half': 252,\n",
       " 'head': 253,\n",
       " 'rememb': 254,\n",
       " 'chang': 255,\n",
       " 'viewer': 256,\n",
       " 'fight': 257,\n",
       " 'gener': 258,\n",
       " 'surpris': 259,\n",
       " 'includ': 260,\n",
       " 'short': 261,\n",
       " 'die': 262,\n",
       " 'fall': 263,\n",
       " 'less': 264,\n",
       " 'els': 265,\n",
       " 'entir': 266,\n",
       " 'piec': 267,\n",
       " 'involv': 268,\n",
       " 'pictur': 269,\n",
       " 'simpli': 270,\n",
       " 'top': 271,\n",
       " 'home': 272,\n",
       " 'power': 273,\n",
       " 'total': 274,\n",
       " 'usual': 275,\n",
       " 'budget': 276,\n",
       " 'attempt': 277,\n",
       " 'suppos': 278,\n",
       " 'releas': 279,\n",
       " 'hollywood': 280,\n",
       " 'terribl': 281,\n",
       " 'song': 282,\n",
       " 'men': 283,\n",
       " 'possibl': 284,\n",
       " 'featur': 285,\n",
       " 'portray': 286,\n",
       " 'disappoint': 287,\n",
       " '3': 288,\n",
       " 'poor': 289,\n",
       " 'coupl': 290,\n",
       " 'camera': 291,\n",
       " 'stupid': 292,\n",
       " 'dead': 293,\n",
       " 'wrong': 294,\n",
       " 'low': 295,\n",
       " 'produc': 296,\n",
       " 'video': 297,\n",
       " 'either': 298,\n",
       " 'aw': 299,\n",
       " 'definit': 300,\n",
       " 'except': 301,\n",
       " 'rest': 302,\n",
       " 'given': 303,\n",
       " 'absolut': 304,\n",
       " 'women': 305,\n",
       " 'lack': 306,\n",
       " 'word': 307,\n",
       " 'writer': 308,\n",
       " 'titl': 309,\n",
       " 'talent': 310,\n",
       " 'decid': 311,\n",
       " 'full': 312,\n",
       " 'perfect': 313,\n",
       " 'along': 314,\n",
       " 'style': 315,\n",
       " 'close': 316,\n",
       " 'truli': 317,\n",
       " 'school': 318,\n",
       " 'save': 319,\n",
       " 'emot': 320,\n",
       " 'age': 321,\n",
       " 'sex': 322,\n",
       " 'next': 323,\n",
       " 'bring': 324,\n",
       " 'mr': 325,\n",
       " 'case': 326,\n",
       " 'killer': 327,\n",
       " 'heart': 328,\n",
       " 'comment': 329,\n",
       " 'sort': 330,\n",
       " 'creat': 331,\n",
       " 'perhap': 332,\n",
       " 'came': 333,\n",
       " 'brother': 334,\n",
       " 'sever': 335,\n",
       " 'joke': 336,\n",
       " 'art': 337,\n",
       " 'dialogu': 338,\n",
       " 'game': 339,\n",
       " 'small': 340,\n",
       " 'base': 341,\n",
       " 'flick': 342,\n",
       " 'written': 343,\n",
       " 'sequenc': 344,\n",
       " 'meet': 345,\n",
       " 'earli': 346,\n",
       " 'often': 347,\n",
       " 'other': 348,\n",
       " 'mother': 349,\n",
       " 'develop': 350,\n",
       " 'humor': 351,\n",
       " 'actress': 352,\n",
       " 'consid': 353,\n",
       " 'dark': 354,\n",
       " 'guess': 355,\n",
       " 'amaz': 356,\n",
       " 'unfortun': 357,\n",
       " 'light': 358,\n",
       " 'lost': 359,\n",
       " 'exampl': 360,\n",
       " 'cinema': 361,\n",
       " 'drama': 362,\n",
       " 'white': 363,\n",
       " 'ye': 364,\n",
       " 'experi': 365,\n",
       " 'imagin': 366,\n",
       " 'mention': 367,\n",
       " 'stop': 368,\n",
       " 'natur': 369,\n",
       " 'forc': 370,\n",
       " 'manag': 371,\n",
       " 'felt': 372,\n",
       " 'cut': 373,\n",
       " 'present': 374,\n",
       " 'children': 375,\n",
       " 'fail': 376,\n",
       " 'son': 377,\n",
       " 'support': 378,\n",
       " 'qualiti': 379,\n",
       " 'car': 380,\n",
       " 'ask': 381,\n",
       " 'hit': 382,\n",
       " 'side': 383,\n",
       " 'voic': 384,\n",
       " 'extrem': 385,\n",
       " 'impress': 386,\n",
       " 'evil': 387,\n",
       " 'wors': 388,\n",
       " 'stand': 389,\n",
       " 'went': 390,\n",
       " 'certainli': 391,\n",
       " 'basic': 392,\n",
       " 'oh': 393,\n",
       " 'overal': 394,\n",
       " 'favorit': 395,\n",
       " 'horribl': 396,\n",
       " 'mysteri': 397,\n",
       " 'number': 398,\n",
       " 'type': 399,\n",
       " 'danc': 400,\n",
       " 'wait': 401,\n",
       " 'hero': 402,\n",
       " '5': 403,\n",
       " 'alreadi': 404,\n",
       " 'learn': 405,\n",
       " 'matter': 406,\n",
       " '4': 407,\n",
       " 'michael': 408,\n",
       " 'genr': 409,\n",
       " 'fine': 410,\n",
       " 'despit': 411,\n",
       " 'throughout': 412,\n",
       " 'walk': 413,\n",
       " 'success': 414,\n",
       " 'histori': 415,\n",
       " 'question': 416,\n",
       " 'zombi': 417,\n",
       " 'town': 418,\n",
       " 'relationship': 419,\n",
       " 'realiz': 420,\n",
       " 'child': 421,\n",
       " 'past': 422,\n",
       " 'daughter': 423,\n",
       " 'late': 424,\n",
       " 'b': 425,\n",
       " 'wish': 426,\n",
       " 'hate': 427,\n",
       " 'credit': 428,\n",
       " 'event': 429,\n",
       " 'theme': 430,\n",
       " 'touch': 431,\n",
       " 'citi': 432,\n",
       " 'today': 433,\n",
       " 'sometim': 434,\n",
       " 'behind': 435,\n",
       " 'god': 436,\n",
       " 'twist': 437,\n",
       " 'sit': 438,\n",
       " 'deal': 439,\n",
       " 'stay': 440,\n",
       " 'annoy': 441,\n",
       " 'abl': 442,\n",
       " 'rent': 443,\n",
       " 'pleas': 444,\n",
       " 'edit': 445,\n",
       " 'blood': 446,\n",
       " 'deserv': 447,\n",
       " 'anyway': 448,\n",
       " 'comic': 449,\n",
       " 'appar': 450,\n",
       " 'soon': 451,\n",
       " 'gave': 452,\n",
       " 'etc': 453,\n",
       " 'level': 454,\n",
       " 'slow': 455,\n",
       " 'chanc': 456,\n",
       " 'score': 457,\n",
       " 'bodi': 458,\n",
       " 'brilliant': 459,\n",
       " 'incred': 460,\n",
       " 'figur': 461,\n",
       " 'situat': 462,\n",
       " 'major': 463,\n",
       " 'self': 464,\n",
       " 'stuff': 465,\n",
       " 'decent': 466,\n",
       " 'element': 467,\n",
       " 'dream': 468,\n",
       " 'return': 469,\n",
       " 'obvious': 470,\n",
       " 'order': 471,\n",
       " 'continu': 472,\n",
       " 'pace': 473,\n",
       " 'ridicul': 474,\n",
       " 'happi': 475,\n",
       " 'add': 476,\n",
       " 'highli': 477,\n",
       " 'group': 478,\n",
       " 'thank': 479,\n",
       " 'ladi': 480,\n",
       " 'novel': 481,\n",
       " 'pain': 482,\n",
       " 'speak': 483,\n",
       " 'career': 484,\n",
       " 'shoot': 485,\n",
       " 'strang': 486,\n",
       " 'heard': 487,\n",
       " 'sad': 488,\n",
       " 'husband': 489,\n",
       " 'polic': 490,\n",
       " 'import': 491,\n",
       " 'break': 492,\n",
       " 'took': 493,\n",
       " 'strong': 494,\n",
       " 'cannot': 495,\n",
       " 'predict': 496,\n",
       " 'robert': 497,\n",
       " 'violenc': 498,\n",
       " 'hilari': 499,\n",
       " 'recent': 500,\n",
       " 'countri': 501,\n",
       " 'known': 502,\n",
       " 'particularli': 503,\n",
       " 'pick': 504,\n",
       " 'documentari': 505,\n",
       " 'season': 506,\n",
       " 'critic': 507,\n",
       " 'jame': 508,\n",
       " 'compar': 509,\n",
       " 'obviou': 510,\n",
       " 'alon': 511,\n",
       " 'told': 512,\n",
       " 'state': 513,\n",
       " 'rock': 514,\n",
       " 'visual': 515,\n",
       " 'offer': 516,\n",
       " 'exist': 517,\n",
       " 'theater': 518,\n",
       " 'opinion': 519,\n",
       " 'gore': 520,\n",
       " 'hold': 521,\n",
       " 'crap': 522,\n",
       " 'result': 523,\n",
       " 'hear': 524,\n",
       " 'room': 525,\n",
       " 'realiti': 526,\n",
       " 'clich': 527,\n",
       " 'effort': 528,\n",
       " 'thriller': 529,\n",
       " 'caus': 530,\n",
       " 'explain': 531,\n",
       " 'serious': 532,\n",
       " 'sequel': 533,\n",
       " 'king': 534,\n",
       " 'local': 535,\n",
       " 'ago': 536,\n",
       " 'hell': 537,\n",
       " 'none': 538,\n",
       " 'note': 539,\n",
       " 'allow': 540,\n",
       " 'sister': 541,\n",
       " 'david': 542,\n",
       " 'simpl': 543,\n",
       " 'femal': 544,\n",
       " 'deliv': 545,\n",
       " 'ok': 546,\n",
       " 'class': 547,\n",
       " 'convinc': 548,\n",
       " 'check': 549,\n",
       " 'suspens': 550,\n",
       " 'win': 551,\n",
       " 'oscar': 552,\n",
       " 'buy': 553,\n",
       " 'huge': 554,\n",
       " 'valu': 555,\n",
       " 'sexual': 556,\n",
       " 'cool': 557,\n",
       " 'scari': 558,\n",
       " 'excit': 559,\n",
       " 'similar': 560,\n",
       " 'exactli': 561,\n",
       " 'apart': 562,\n",
       " 'provid': 563,\n",
       " 'avoid': 564,\n",
       " 'shown': 565,\n",
       " 'seriou': 566,\n",
       " 'english': 567,\n",
       " 'whose': 568,\n",
       " 'taken': 569,\n",
       " 'cinematographi': 570,\n",
       " 'shock': 571,\n",
       " 'polit': 572,\n",
       " 'spoiler': 573,\n",
       " 'offic': 574,\n",
       " 'across': 575,\n",
       " 'middl': 576,\n",
       " 'pass': 577,\n",
       " 'street': 578,\n",
       " 'messag': 579,\n",
       " 'silli': 580,\n",
       " 'somewhat': 581,\n",
       " 'charm': 582,\n",
       " 'modern': 583,\n",
       " 'confus': 584,\n",
       " 'filmmak': 585,\n",
       " 'form': 586,\n",
       " 'tale': 587,\n",
       " 'singl': 588,\n",
       " 'jack': 589,\n",
       " 'mostli': 590,\n",
       " 'attent': 591,\n",
       " 'william': 592,\n",
       " 'carri': 593,\n",
       " 'sing': 594,\n",
       " 'five': 595,\n",
       " 'subject': 596,\n",
       " 'prove': 597,\n",
       " 'richard': 598,\n",
       " 'stage': 599,\n",
       " 'team': 600,\n",
       " 'unlik': 601,\n",
       " 'cop': 602,\n",
       " 'georg': 603,\n",
       " 'televis': 604,\n",
       " 'monster': 605,\n",
       " 'earth': 606,\n",
       " 'villain': 607,\n",
       " 'cover': 608,\n",
       " 'pay': 609,\n",
       " 'marri': 610,\n",
       " 'toward': 611,\n",
       " 'build': 612,\n",
       " 'parent': 613,\n",
       " 'pull': 614,\n",
       " 'due': 615,\n",
       " 'respect': 616,\n",
       " 'fill': 617,\n",
       " 'dialog': 618,\n",
       " 'four': 619,\n",
       " 'remind': 620,\n",
       " 'futur': 621,\n",
       " 'weak': 622,\n",
       " 'typic': 623,\n",
       " '7': 624,\n",
       " 'cheap': 625,\n",
       " 'intellig': 626,\n",
       " 'atmospher': 627,\n",
       " 'british': 628,\n",
       " 'clearli': 629,\n",
       " '80': 630,\n",
       " 'paul': 631,\n",
       " 'non': 632,\n",
       " 'dog': 633,\n",
       " 'artist': 634,\n",
       " 'knew': 635,\n",
       " 'fast': 636,\n",
       " '8': 637,\n",
       " 'crime': 638,\n",
       " 'easili': 639,\n",
       " 'escap': 640,\n",
       " 'adult': 641,\n",
       " 'doubt': 642,\n",
       " 'detail': 643,\n",
       " 'date': 644,\n",
       " 'fire': 645,\n",
       " 'romant': 646,\n",
       " 'member': 647,\n",
       " 'drive': 648,\n",
       " 'gun': 649,\n",
       " 'straight': 650,\n",
       " 'fit': 651,\n",
       " 'beyond': 652,\n",
       " 'attack': 653,\n",
       " 'imag': 654,\n",
       " 'upon': 655,\n",
       " 'posit': 656,\n",
       " 'whether': 657,\n",
       " 'peter': 658,\n",
       " 'fantast': 659,\n",
       " 'aspect': 660,\n",
       " 'appreci': 661,\n",
       " 'captur': 662,\n",
       " 'ten': 663,\n",
       " 'plan': 664,\n",
       " 'discov': 665,\n",
       " 'remain': 666,\n",
       " 'period': 667,\n",
       " 'near': 668,\n",
       " 'realist': 669,\n",
       " 'air': 670,\n",
       " 'mark': 671,\n",
       " 'red': 672,\n",
       " 'dull': 673,\n",
       " 'adapt': 674,\n",
       " 'within': 675,\n",
       " 'lose': 676,\n",
       " 'spend': 677,\n",
       " 'color': 678,\n",
       " 'materi': 679,\n",
       " 'chase': 680,\n",
       " 'mari': 681,\n",
       " 'storylin': 682,\n",
       " 'forget': 683,\n",
       " 'bunch': 684,\n",
       " 'clear': 685,\n",
       " 'lee': 686,\n",
       " 'victim': 687,\n",
       " 'nearli': 688,\n",
       " 'box': 689,\n",
       " 'york': 690,\n",
       " 'match': 691,\n",
       " 'inspir': 692,\n",
       " 'finish': 693,\n",
       " 'mess': 694,\n",
       " 'standard': 695,\n",
       " 'easi': 696,\n",
       " 'truth': 697,\n",
       " 'suffer': 698,\n",
       " 'busi': 699,\n",
       " 'bill': 700,\n",
       " 'dramat': 701,\n",
       " 'space': 702,\n",
       " 'western': 703,\n",
       " 'e': 704,\n",
       " 'list': 705,\n",
       " 'battl': 706,\n",
       " 'notic': 707,\n",
       " 'de': 708,\n",
       " 'french': 709,\n",
       " 'ad': 710,\n",
       " '9': 711,\n",
       " 'tom': 712,\n",
       " 'larg': 713,\n",
       " 'among': 714,\n",
       " 'eventu': 715,\n",
       " 'accept': 716,\n",
       " 'train': 717,\n",
       " 'agre': 718,\n",
       " 'spirit': 719,\n",
       " 'soundtrack': 720,\n",
       " 'third': 721,\n",
       " 'teenag': 722,\n",
       " 'adventur': 723,\n",
       " 'soldier': 724,\n",
       " 'drug': 725,\n",
       " 'suggest': 726,\n",
       " 'sorri': 727,\n",
       " 'famou': 728,\n",
       " 'cri': 729,\n",
       " 'babi': 730,\n",
       " 'normal': 731,\n",
       " 'troubl': 732,\n",
       " 'ultim': 733,\n",
       " 'contain': 734,\n",
       " 'certain': 735,\n",
       " 'cultur': 736,\n",
       " 'romanc': 737,\n",
       " 'rare': 738,\n",
       " 'lame': 739,\n",
       " 'somehow': 740,\n",
       " 'mix': 741,\n",
       " 'disney': 742,\n",
       " 'gone': 743,\n",
       " 'cartoon': 744,\n",
       " 'student': 745,\n",
       " 'reveal': 746,\n",
       " 'fear': 747,\n",
       " 'kept': 748,\n",
       " 'suck': 749,\n",
       " 'attract': 750,\n",
       " 'appeal': 751,\n",
       " 'premis': 752,\n",
       " 'secret': 753,\n",
       " 'design': 754,\n",
       " 'greatest': 755,\n",
       " 'shame': 756,\n",
       " 'throw': 757,\n",
       " 'scare': 758,\n",
       " 'copi': 759,\n",
       " 'wit': 760,\n",
       " 'admit': 761,\n",
       " 'america': 762,\n",
       " 'relat': 763,\n",
       " 'brought': 764,\n",
       " 'particular': 765,\n",
       " 'screenplay': 766,\n",
       " 'whatev': 767,\n",
       " 'pure': 768,\n",
       " '70': 769,\n",
       " 'averag': 770,\n",
       " 'harri': 771,\n",
       " 'master': 772,\n",
       " 'describ': 773,\n",
       " 'male': 774,\n",
       " 'treat': 775,\n",
       " '20': 776,\n",
       " 'fantasi': 777,\n",
       " 'issu': 778,\n",
       " 'warn': 779,\n",
       " 'inde': 780,\n",
       " 'background': 781,\n",
       " 'forward': 782,\n",
       " 'free': 783,\n",
       " 'project': 784,\n",
       " 'memor': 785,\n",
       " 'japanes': 786,\n",
       " 'poorli': 787,\n",
       " 'award': 788,\n",
       " 'locat': 789,\n",
       " 'potenti': 790,\n",
       " 'amus': 791,\n",
       " 'struggl': 792,\n",
       " 'weird': 793,\n",
       " 'magic': 794,\n",
       " 'societi': 795,\n",
       " 'okay': 796,\n",
       " 'accent': 797,\n",
       " 'imdb': 798,\n",
       " 'doctor': 799,\n",
       " 'hot': 800,\n",
       " 'water': 801,\n",
       " '30': 802,\n",
       " 'express': 803,\n",
       " 'dr': 804,\n",
       " 'alien': 805,\n",
       " 'odd': 806,\n",
       " 'choic': 807,\n",
       " 'crazi': 808,\n",
       " 'fiction': 809,\n",
       " 'studio': 810,\n",
       " 'becam': 811,\n",
       " 'control': 812,\n",
       " 'masterpiec': 813,\n",
       " 'difficult': 814,\n",
       " 'fli': 815,\n",
       " 'joe': 816,\n",
       " 'scream': 817,\n",
       " 'costum': 818,\n",
       " 'lover': 819,\n",
       " 'refer': 820,\n",
       " 'uniqu': 821,\n",
       " 'remak': 822,\n",
       " 'girlfriend': 823,\n",
       " 'vampir': 824,\n",
       " 'prison': 825,\n",
       " 'execut': 826,\n",
       " 'wear': 827,\n",
       " 'jump': 828,\n",
       " 'wood': 829,\n",
       " 'unless': 830,\n",
       " 'creepi': 831,\n",
       " 'cheesi': 832,\n",
       " 'superb': 833,\n",
       " 'otherwis': 834,\n",
       " 'parti': 835,\n",
       " 'ghost': 836,\n",
       " 'roll': 837,\n",
       " 'mad': 838,\n",
       " 'public': 839,\n",
       " 'depict': 840,\n",
       " 'jane': 841,\n",
       " 'moral': 842,\n",
       " 'earlier': 843,\n",
       " 'badli': 844,\n",
       " 'week': 845,\n",
       " 'dumb': 846,\n",
       " 'fi': 847,\n",
       " 'flaw': 848,\n",
       " 'grow': 849,\n",
       " 'deep': 850,\n",
       " 'sci': 851,\n",
       " 'cat': 852,\n",
       " 'maker': 853,\n",
       " 'older': 854,\n",
       " 'connect': 855,\n",
       " 'footag': 856,\n",
       " 'bother': 857,\n",
       " 'plenti': 858,\n",
       " 'outsid': 859,\n",
       " 'stick': 860,\n",
       " 'gay': 861,\n",
       " 'catch': 862,\n",
       " 'plu': 863,\n",
       " 'co': 864,\n",
       " 'popular': 865,\n",
       " 'equal': 866,\n",
       " 'social': 867,\n",
       " 'quickli': 868,\n",
       " 'disturb': 869,\n",
       " 'perfectli': 870,\n",
       " 'dress': 871,\n",
       " 'era': 872,\n",
       " '90': 873,\n",
       " 'mistak': 874,\n",
       " 'lie': 875,\n",
       " 'previou': 876,\n",
       " 'ride': 877,\n",
       " 'combin': 878,\n",
       " 'concept': 879,\n",
       " 'band': 880,\n",
       " 'answer': 881,\n",
       " 'surviv': 882,\n",
       " 'rich': 883,\n",
       " 'front': 884,\n",
       " 'christma': 885,\n",
       " 'sweet': 886,\n",
       " 'insid': 887,\n",
       " 'bare': 888,\n",
       " 'eat': 889,\n",
       " 'concern': 890,\n",
       " 'beat': 891,\n",
       " 'listen': 892,\n",
       " 'ben': 893,\n",
       " 'c': 894,\n",
       " 'serv': 895,\n",
       " 'term': 896,\n",
       " 'meant': 897,\n",
       " 'la': 898,\n",
       " 'german': 899,\n",
       " 'hardli': 900,\n",
       " 'stereotyp': 901,\n",
       " 'law': 902,\n",
       " 'innoc': 903,\n",
       " 'desper': 904,\n",
       " 'promis': 905,\n",
       " 'memori': 906,\n",
       " 'cute': 907,\n",
       " 'intent': 908,\n",
       " 'variou': 909,\n",
       " 'inform': 910,\n",
       " 'steal': 911,\n",
       " 'brain': 912,\n",
       " 'post': 913,\n",
       " 'tone': 914,\n",
       " 'island': 915,\n",
       " 'amount': 916,\n",
       " 'compani': 917,\n",
       " 'nuditi': 918,\n",
       " 'track': 919,\n",
       " 'store': 920,\n",
       " 'claim': 921,\n",
       " 'hair': 922,\n",
       " 'flat': 923,\n",
       " '50': 924,\n",
       " 'univers': 925,\n",
       " 'land': 926,\n",
       " 'kick': 927,\n",
       " 'danger': 928,\n",
       " 'scott': 929,\n",
       " 'fairli': 930,\n",
       " 'player': 931,\n",
       " 'plain': 932,\n",
       " 'step': 933,\n",
       " 'crew': 934,\n",
       " 'toni': 935,\n",
       " 'share': 936,\n",
       " 'centuri': 937,\n",
       " 'tast': 938,\n",
       " 'achiev': 939,\n",
       " 'engag': 940,\n",
       " 'travel': 941,\n",
       " 'cold': 942,\n",
       " 'suit': 943,\n",
       " 'rip': 944,\n",
       " 'record': 945,\n",
       " 'manner': 946,\n",
       " 'sadli': 947,\n",
       " 'spot': 948,\n",
       " 'tension': 949,\n",
       " 'wrote': 950,\n",
       " 'fascin': 951,\n",
       " 'intens': 952,\n",
       " 'familiar': 953,\n",
       " 'remark': 954,\n",
       " 'burn': 955,\n",
       " 'depth': 956,\n",
       " 'histor': 957,\n",
       " 'destroy': 958,\n",
       " 'sleep': 959,\n",
       " 'purpos': 960,\n",
       " 'languag': 961,\n",
       " 'ruin': 962,\n",
       " 'ignor': 963,\n",
       " 'delight': 964,\n",
       " 'unbeliev': 965,\n",
       " 'italian': 966,\n",
       " 'abil': 967,\n",
       " 'collect': 968,\n",
       " 'soul': 969,\n",
       " 'clever': 970,\n",
       " 'detect': 971,\n",
       " 'violent': 972,\n",
       " 'rape': 973,\n",
       " 'reach': 974,\n",
       " 'door': 975,\n",
       " 'liter': 976,\n",
       " 'trash': 977,\n",
       " 'scienc': 978,\n",
       " 'commun': 979,\n",
       " 'reveng': 980,\n",
       " 'caught': 981,\n",
       " 'creatur': 982,\n",
       " 'approach': 983,\n",
       " 'trip': 984,\n",
       " 'fashion': 985,\n",
       " 'intrigu': 986,\n",
       " 'skill': 987,\n",
       " 'introduc': 988,\n",
       " 'paint': 989,\n",
       " 'complex': 990,\n",
       " 'channel': 991,\n",
       " 'camp': 992,\n",
       " 'christian': 993,\n",
       " 'extra': 994,\n",
       " 'hole': 995,\n",
       " 'limit': 996,\n",
       " 'immedi': 997,\n",
       " 'mental': 998,\n",
       " 'ann': 999,\n",
       " 'million': 1000,\n",
       " 'comput': 1001,\n",
       " ...}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_dict = build_dict(train_X)\n",
    "word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['movi', 'film', 'one', 'like', 'time']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_five = []\n",
    "for word, index in word_dict.items():\n",
    "    if len(top_five) >= 5:\n",
    "        break\n",
    "    top_five.append(word)\n",
    "top_five"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data/pytorch' \n",
    "if not os.path.exists(data_dir): \n",
    "    os.makedirs(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, 'word_dict.pkl'), \"wb\") as f:\n",
    "    pickle.dump(word_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_and_pad(word_dict, sentence, pad=500):\n",
    "    NOWORD = 0 \n",
    "    INFREQ = 1 \n",
    "    \n",
    "    working_sentence = [NOWORD] * pad\n",
    "    \n",
    "    for word_index, word in enumerate(sentence[:pad]):\n",
    "        if word in word_dict:\n",
    "            working_sentence[word_index] = word_dict[word]\n",
    "        else:\n",
    "            working_sentence[word_index] = INFREQ\n",
    "            \n",
    "    return working_sentence, min(len(sentence), pad)\n",
    "\n",
    "def convert_and_pad_data(word_dict, data, pad=500):\n",
    "    result = []\n",
    "    lengths = []\n",
    "    \n",
    "    for sentence in data:\n",
    "        converted, leng = convert_and_pad(word_dict, sentence, pad)\n",
    "        result.append(converted)\n",
    "        lengths.append(leng)\n",
    "        \n",
    "    return np.array(result), np.array(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_X_len = convert_and_pad_data(word_dict, train_X)\n",
    "test_X, test_X_len = convert_and_pad_data(word_dict, test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  47,  480,  672, ...,    0,    0,    0],\n",
       "       [   2, 4248,    1, ...,    0,    0,    0],\n",
       "       [2117,  334, 1681, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [ 466,  192,    1, ...,    0,    0,    0],\n",
       "       [ 254,  214,  326, ...,    0,    0,    0],\n",
       "       [1009,  342,  357, ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 591  573   46   23  512 1016 2043 1573 2681  174    2  562   21 4967\n",
      "   90    3  311   11   79  132 1422   47    2  172 2251   12 2310 1573\n",
      " 2681    2   59 1573 2681    2  311  184  113  685  822  728    3 1016\n",
      " 2043 3204 1386 1310   30   59 1573 2681  371    3 1239  793   33   17\n",
      "    1 1205  404 2956 2681    2  178    5    4    3   14  848 3185    1\n",
      " 1994    1  871 2043  177   43   36  129 2750 1442    1  265    3   57\n",
      "   98   28  145  881  416  523 1573 2681 4641  331  822   28 2681 2681\n",
      " 1455  167  822   87  366  228 2681   37  139   93  256    2   47   28\n",
      "    3  197   76 4781 2886  220   37  822  517  129 1292   42    3  368\n",
      "  509   33 1534   93  169    3  704 1121    1 1633  890   13  117 2681\n",
      "  459  193  881  249  416   90   28  648  144  179 3671  958  108    1\n",
      "   22    2  573 3642   45   64  606   61  887   92   39 1101 2043 1311\n",
      "    1  881   23  149  521 3281  571   22   28 1016 2043   22   14 1849\n",
      " 3281  146  584 2714  909 1016 2043    1    1    8  196  495  152 1719\n",
      "    4  128    1 1573 2681   33 2371  339 4448   17 2681  123  142    5\n",
      "  348  121   62 2327 1774  330    1   17   30  296   56  381 2681   97\n",
      "  822    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0]\n",
      "225\n"
     ]
    }
   ],
   "source": [
    "print(train_X[100])\n",
    "print(train_X_len[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.0' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "    \n",
    "pd.concat([pd.DataFrame(train_y), pd.DataFrame(train_X_len), pd.DataFrame(train_X)], axis=1) \\\n",
    "        .to_csv(os.path.join(data_dir, 'train.csv'), header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = 'sagemaker/sentiment_rnn'\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = sagemaker_session.upload_data(path=data_dir, bucket=bucket, key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (0.16.1)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torchvision) (1.22.4)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: torch==2.1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torchvision) (2.1.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torchvision) (10.0.1)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.1.1->torchvision) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.1.1->torchvision) (4.8.0)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.1.1->torchvision) (1.12)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.1.1->torchvision) (3.2)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.1.1->torchvision) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.1.1->torchvision) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.1.1->torchvision) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.1.1->torchvision) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.1.1->torchvision) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.1.1->torchvision) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.1.1->torchvision) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.1.1->torchvision) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.1.1->torchvision) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.1.1->torchvision) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.1.1->torchvision) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.1.1->torchvision) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.1.1->torchvision) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.1.1->torchvision) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.1->torchvision) (12.3.101)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->torchvision) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->torchvision) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->torchvision) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jinja2->torch==2.1.1->torchvision) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sympy->torch==2.1.1->torchvision) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "train_sample = pd.read_csv(os.path.join(data_dir, 'train.csv'), header=None, names=None, nrows=250)\n",
    "train_sample_y = torch.from_numpy(train_sample[[0]].values).float().squeeze()\n",
    "train_sample_X = torch.from_numpy(train_sample.drop([0], axis=1).values).long()\n",
    "train_sample_ds = torch.utils.data.TensorDataset(train_sample_X, train_sample_y)\n",
    "train_sample_dl = torch.utils.data.DataLoader(train_sample_ds, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, epochs, optimizer, loss_fn, device):\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch in train_loader:         \n",
    "            batch_X, batch_y = batch\n",
    "            \n",
    "            batch_X = batch_X.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            out = model.forward(batch_X)\n",
    "            loss = loss_fn(out, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.data.item()\n",
    "        print(\"Epoch: {}, BCELoss: {}\".format(epoch, total_loss / len(train_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Epoch: 1, BCELoss: 0.6927214384078979\n",
      "Epoch: 2, BCELoss: 0.6826396107673645\n",
      "Epoch: 3, BCELoss: 0.6736706495285034\n",
      "Epoch: 4, BCELoss: 0.6635082960128784\n",
      "Epoch: 5, BCELoss: 0.6507992506027221\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from train.model import LSTMClassifier\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model = LSTMClassifier(32, 100, 5000).to(device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "\n",
    "train(model, train_sample_dl, 5, optimizer, loss_fn, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: pytorch-training-2023-11-20-06-14-08-087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n",
      "2023-11-20 06:14:08 Starting - Starting the training job...\n",
      "2023-11-20 06:14:33 Starting - Preparing the instances for training.........\n",
      "2023-11-20 06:15:55 Downloading - Downloading input data...\n",
      "2023-11-20 06:16:30 Training - Downloading the training image......\n",
      "2023-11-20 06:17:25 Training - Training image download completed. Training in progress..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2023-11-20 06:17:40,399 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2023-11-20 06:17:40,402 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-11-20 06:17:40,413 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2023-11-20 06:17:40,416 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2023-11-20 06:17:40,620 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 1)) (1.1.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 2)) (1.19.1)\u001b[0m\n",
      "\u001b[34mCollecting nltk\n",
      "  Downloading nltk-3.6.7-py3-none-any.whl (1.5 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 4)) (4.10.0)\u001b[0m\n",
      "\u001b[34mCollecting html5lib\n",
      "  Downloading html5lib-1.1-py2.py3-none-any.whl (112 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.6/site-packages (from pandas->-r requirements.txt (line 1)) (2.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.6/site-packages (from pandas->-r requirements.txt (line 1)) (2021.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (from nltk->-r requirements.txt (line 3)) (4.61.2)\u001b[0m\n",
      "\u001b[34mCollecting regex>=2021.8.3\n",
      "  Downloading regex-2023.8.8-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (759 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: click in /opt/conda/lib/python3.6/site-packages (from nltk->-r requirements.txt (line 3)) (8.0.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from nltk->-r requirements.txt (line 3)) (1.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.6/site-packages (from beautifulsoup4->-r requirements.txt (line 4)) (2.3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: webencodings in /opt/conda/lib/python3.6/site-packages (from html5lib->-r requirements.txt (line 5)) (0.5.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.9 in /opt/conda/lib/python3.6/site-packages (from html5lib->-r requirements.txt (line 5)) (1.16.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.6/site-packages (from click->nltk->-r requirements.txt (line 3)) (4.8.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata->click->nltk->-r requirements.txt (line 3)) (3.10.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata->click->nltk->-r requirements.txt (line 3)) (3.6.0)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: regex, nltk, html5lib\u001b[0m\n",
      "\u001b[34mSuccessfully installed html5lib-1.1 nltk-3.6.7 regex-2023.8.8\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m2023-11-20 06:17:45,569 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-11-20 06:17:45,586 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-11-20 06:17:45,600 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-11-20 06:17:45,612 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 10,\n",
      "        \"hidden_dim\": 200\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2023-11-20-06-14-08-087\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-575437452043/pytorch-training-2023-11-20-06-14-08-087/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m4.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m4.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":10,\"hidden_dim\":200}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m4.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m4.xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-575437452043/pytorch-training-2023-11-20-06-14-08-087/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":10,\"hidden_dim\":200},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2023-11-20-06-14-08-087\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-575437452043/pytorch-training-2023-11-20-06-14-08-087/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m4.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m4.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"10\",\"--hidden_dim\",\"200\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=10\u001b[0m\n",
      "\u001b[34mSM_HP_HIDDEN_DIM=200\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 train.py --epochs 10 --hidden_dim 200\u001b[0m\n",
      "\u001b[34mUsing device cpu.\u001b[0m\n",
      "\u001b[34mGet train data loader.\u001b[0m\n",
      "\u001b[34mModel loaded with embedding_dim 32, hidden_dim 200, vocab_size 5000.\u001b[0m\n",
      "\u001b[34m[2023-11-20 06:17:47.943 algo-1:34 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2023-11-20 06:17:48.179 algo-1:34 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2023-11-20 06:17:48.180 algo-1:34 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2023-11-20 06:17:48.181 algo-1:34 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2023-11-20 06:17:48.181 algo-1:34 INFO hook.py:255] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2023-11-20 06:17:48.182 algo-1:34 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2023-11-20 06:17:48.189 algo-1:34 INFO hook.py:591] name:weight count_params:160000\u001b[0m\n",
      "\u001b[34m[2023-11-20 06:17:48.189 algo-1:34 INFO hook.py:593] Total Trainable Params: 160000\u001b[0m\n",
      "\u001b[34m[2023-11-20 06:17:48.189 algo-1:34 INFO hook.py:425] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2023-11-20 06:17:48.192 algo-1:34 INFO hook.py:488] Hook is writing from the hook with pid: 34\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mEpoch: 1, BCELoss: 0.6690408940217933\u001b[0m\n",
      "\u001b[34mEpoch: 2, BCELoss: 0.5850774889089623\u001b[0m\n",
      "\u001b[34mEpoch: 3, BCELoss: 0.5253639409736711\u001b[0m\n",
      "\u001b[34mEpoch: 4, BCELoss: 0.448875014271055\u001b[0m\n",
      "\u001b[34mEpoch: 5, BCELoss: 0.4460091006999113\u001b[0m\n",
      "\u001b[34mEpoch: 6, BCELoss: 0.38000536208250085\u001b[0m\n",
      "\u001b[34mEpoch: 7, BCELoss: 0.33870953078172644\u001b[0m\n",
      "\u001b[34mEpoch: 8, BCELoss: 0.3191174469432052\u001b[0m\n",
      "\u001b[34mEpoch: 9, BCELoss: 0.30293984133370067\u001b[0m\n",
      "\n",
      "2023-11-20 07:01:36 Uploading - Uploading generated training model\u001b[34mEpoch: 10, BCELoss: 0.2937456564027436\u001b[0m\n",
      "\u001b[34m2023-11-20 07:01:30,474 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2023-11-20 07:01:52 Completed - Training job completed\n",
      "Training seconds: 2757\n",
      "Billable seconds: 2757\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "estimator = PyTorch(entry_point=\"train.py\",\n",
    "                    source_dir=\"train\",\n",
    "                    role=role,\n",
    "                    framework_version='1.8.1',  \n",
    "                    py_version=\"py3\",   \n",
    "                    train_instance_count=1,\n",
    "                    train_instance_type='ml.m4.xlarge', \n",
    "                    hyperparameters={\n",
    "                        'epochs': 10,\n",
    "                        'hidden_dim': 200,\n",
    "                    })\n",
    "\n",
    "estimator.fit({'training': input_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_predictor = estimator.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = pd.concat([pd.DataFrame(test_X_len), pd.DataFrame(test_X)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data, rows=512):\n",
    "    split_array = np.array_split(data, int(data.shape[0] / float(rows) + 1))\n",
    "    predictions = np.array([])\n",
    "    for array in split_array:\n",
    "        predictions = np.append(predictions, estimator_predictor.predict(array))\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict(test_X.values)\n",
    "predictions = [round(num) for num in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(test_y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_review = 'The simplest pleasures in life are the best, and this film is one of them. Combining a rather basic storyline of love and adventure this movie transcends the usual weekend fair with wit and unmitigated charm.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_review_X, test_review_len = convert_and_pad(word_dict, review_to_words(test_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.hstack((test_review_len, test_review_X))\n",
    "test_data = test_data.reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtest_data\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_data' is not defined"
     ]
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'estimator_predictor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mestimator_predictor\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(test_data)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'estimator_predictor' is not defined"
     ]
    }
   ],
   "source": [
    "estimator_predictor.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
